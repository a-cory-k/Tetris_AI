# ğŸ® Tetris AI
*Research project exploring AI agents in the Tetris environment using Reinforcement Learning and Deep Neural Networks.*

<p align="center">
  <img src="https://img.shields.io/badge/status-Work%20in%20Progress-orange" />
  <img src="https://img.shields.io/badge/AI-DQN%2C%20CNN%2C%20LSTM-blue" />
  <img src="https://img.shields.io/badge/license-MIT-green" />
</p>

---

## ğŸš€ Overview
This project is an experimental framework for developing and evaluating AI agents that play **Tetris**. The goal is to compare different learning strategiesâ€”such as **Deep Q-Networks (DQN)**, **Convolutional Neural Networks (CNN)**, **LSTM-based actors** (in process),**Graph Neural Networks (GNNs)** (in process), and **heuristic-based methods**â€”in terms of performance, stability, and learning efficiency.

The project is actively under development and serves as a research environment for reinforcement learning, neural architectures, and dataset-driven policy optimization.

---

## ğŸ“‚ Repository Structure
```plaintext
â”œâ”€â”€ README.md                # Project documentation
â”œâ”€â”€ main.py                 # Entry point to run the game or selected AI agent
â”œâ”€â”€ app/
â”‚   â””â”€â”€ tetris_dual.py      # Core Tetris game engine
â”œâ”€â”€ bots/                   # AI agents
â”‚   â”œâ”€â”€ heuristic_bot.py        # Rule-based baseline bot
â”‚   â”œâ”€â”€ cnn_bot.py              # CNN-based inference agent
â”‚   â”œâ”€â”€ dqn_bot_CNN.py          # DQN agent using CNN architecture
â”‚   â”œâ”€â”€ DONT_WORK(lstm_bot).py  # Experimental LSTM-based agent (not fully functional)
â”‚   â””â”€â”€ cnn_training/           # Training environment for DQN agents
â”‚       â”œâ”€â”€ tetris_env_cnn.py
â”‚       â”œâ”€â”€ tetris_play_cnn.py
â”‚       â””â”€â”€ tetris_train_cnn.py
â”œâ”€â”€ datasets/               # Pre-collected gameplay data for training / evaluation
â”‚   â”œâ”€â”€ tetris_dataset_v1.csv
â”‚   â”œâ”€â”€ tetris_dataset_v2.csv
â”‚   â””â”€â”€ tetris_dataset_cnn_XX.csv
â”œâ”€â”€ models/                 # Trained models and weights
â”‚   â”œâ”€â”€ tetris_cnn.pth
â”‚   â”œâ”€â”€ tetris_dqn_v1.pth
â”‚   â”œâ”€â”€ tetris_dqn_v2.pth
â”‚   â””â”€â”€ tetris_actor_lstm.pth
â”œâ”€â”€ notebooks/             # Interactive training experiments
â”‚   â”œâ”€â”€ CNN.ipynb
â”‚   â””â”€â”€ LSTMactor.ipynb
â””â”€â”€ tools/                 # Data generation utilities
    â”œâ”€â”€ dataset_generator.py
    â””â”€â”€ dataset_generator_random.py
```
## ğŸ›  Installation
```
git clone https://github.com/a-cory-k/Tetris_AI.git
cd Tetris_AI
pip install -r requirements.txt
```
# â–¶ï¸ Usage
Run the main script:
```
python main.py
```
After starting, a **main menu** will appear. You can choose one of the following modes:

| Mode | Description | Notes |
|------|-------------|-------|
| ğŸ® **Player vs Player (PVP)** | Compete against a friend on the same computer. | Both players control their own tetrominoes. |
| ğŸ¤– **Player vs Bot (PVB)** | Play against an AI agent. | You can select which bot to compete against (CNN, DQN, or Heuristic). |
| âš”ï¸ **Bot vs Bot (BVB)** | Watch two AI agents play against each other. | Useful for testing AI strategies and comparing performance. |
| ğŸ•¹ï¸ **Single Player (SP)** | Play alone or watch a single AI agent play. | Choose a bot to observe its gameplay, or play manually yourself. |





